.. _getting_started:

Getting Started Guide
=====================

``peak-shaver`` aims to provide the tools to explore different approaches of reinforcement learning within a simulation of the `HIPE Dataset <https://www.energystatusdata.kit.edu/hipe.php>`_. The module for the simulation ``common_env`` is made as a ``gym`` environment, which provides a common API for a wide range of different RL-libraries (for example ``stable-baseline`` which is also used as part of the study project). You can also create your own Agents following the ``gym`` guide-lines. Note that ``common_env`` requires some extra methods (look up the :ref:`module <common_env_doc>`) which will also be explained in this guide. For example is ``reward_maker`` used to specify the kind of reward the agent will receive.

Installation
************
- github install
- dependencies installation

Folder Structure
****************
- wie ordner mit daten heißen muss

Data Preparation
****************
- schaffer explanation

Making Predictions
******************
- example lstm predictions with specific timeframe

Basic RL-Agent with in-depth explanation
***************************************
- im gegensatz zu examples wird hier genau der aufbau erklärt (tut style)

