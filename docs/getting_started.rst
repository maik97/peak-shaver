.. _getting_started:

Getting Started Guide
=====================

``peak-shaver`` aims to provide the tools to explore different approaches of reinforcement learning within a simulation of the HIPE-Dataset. The module ``common_env`` is made as a `gym`` environment, which provides a common API for a wide range for different RL-libraries (for example ``stable-baseline`` which is also used a part of the study project). You can also create your own Agents following the ``gym`` guide-lines. Note that ``common_env`` requires some extra methods (look up the :ref:`module <common_env_doc>`) which will also be explained in this guide. For example is ``reward_maker`` used to specify the kind of reward the agent will receive.


Installation
************
- github install
- dependencies installation

Folder Structure
****************
- wie ordner mit daten heißen muss

Data Preparation
****************
- schaffer explanation

Making Predictions
******************
- example lstm predictions with specific timeframe

Basic RL-Agent with indepth explanation
***************************************
- im gegensatz zu examples wird hier genau der aufbau erklärt (tut style)

